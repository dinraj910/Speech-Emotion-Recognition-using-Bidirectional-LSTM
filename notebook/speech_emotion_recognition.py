# -*- coding: utf-8 -*-
"""Speech_Emotion_Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pR4T76NBLyIB8DZ8xI-CvfMaMeT1H2wA

## Environment Setup
"""

!pip install -q kaggle librosa soundfile joblib seaborn

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import librosa
import librosa.display
import soundfile as sf
import joblib
import json

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input, LSTM, Dense, Dropout,
    Bidirectional, Masking
)
from tensorflow.keras.callbacks import (
    EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
)
from tensorflow.keras.utils import to_categorical

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split

tf.random.set_seed(42)
np.random.seed(42)

"""## Kaggle Dataset Loading"""

from google.colab import files
files.upload()  # Upload kaggle.json

os.makedirs('/root/.kaggle', exist_ok=True)
!mv kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d ejlok1/cremad
!unzip -q cremad.zip

DATA_PATH = "/content/AudioWAV"

print("Total files:", len(os.listdir(DATA_PATH)))

"""## Label Parsing & Emotion Filtering"""

emotion_map = {
    "ANG": 0,
    "HAP": 1,
    "SAD": 2,
    "DIS": 3
}

file_paths = []
labels = []

for file in os.listdir(DATA_PATH):
    emotion_code = file.split("_")[2]

    if emotion_code in emotion_map:
        file_paths.append(os.path.join(DATA_PATH, file))
        labels.append(emotion_map[emotion_code])

print("Filtered samples:", len(file_paths))

"""## Feature Extraction Pipeline"""

SAMPLE_RATE = 16000
N_MFCC = 40
MAX_FRAMES = 400

def extract_features(file_path):
    y, sr = librosa.load(file_path, sr=SAMPLE_RATE)

    # Trim silence
    y, _ = librosa.effects.trim(y)

    # MFCC
    mfcc = librosa.feature.mfcc(
        y=y, sr=sr,
        n_mfcc=N_MFCC,
        n_fft=400,
        hop_length=160
    )

    # Delta
    delta = librosa.feature.delta(mfcc)
    delta2 = librosa.feature.delta(mfcc, order=2)

    features = np.vstack([mfcc, delta, delta2])
    features = features.T  # (T, 120)

    return features

"""## Build Dataset"""

# ============================================================
# 6. DATASET BUILDING
# ============================================================

def pad_or_truncate(features):
    if features.shape[0] > MAX_FRAMES:
        return features[:MAX_FRAMES]
    else:
        pad_width = MAX_FRAMES - features.shape[0]
        return np.pad(features, ((0, pad_width), (0, 0)), mode='constant')

X = []
y = []

for path, label in zip(file_paths, labels):
    features = extract_features(path)
    features = pad_or_truncate(features)
    X.append(features)
    y.append(label)

X = np.array(X)
y = np.array(y)

print("Final shape:", X.shape)

"""## Standardization"""

scaler = StandardScaler()

X_reshaped = X.reshape(-1, X.shape[-1])
scaler.fit(X_reshaped)

X_scaled = scaler.transform(X_reshaped).reshape(X.shape)

joblib.dump(scaler, "scaler.pkl")

"""## Train/Test Split"""

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y,
    test_size=0.2,
    stratify=y,
    random_state=42
)

y_train = to_categorical(y_train, 4)
y_test = to_categorical(y_test, 4)

"""## Model Architecture"""

input_layer = Input(shape=(MAX_FRAMES, 120))

x = Masking(mask_value=0.0)(input_layer)

x = Bidirectional(LSTM(128, return_sequences=True))(x)
x = Dropout(0.4)(x)

x = Bidirectional(LSTM(64))(x)
x = Dropout(0.4)(x)

x = Dense(64, activation='relu')(x)
x = Dropout(0.3)(x)

output = Dense(4, activation='softmax')(x)

model = Model(inputs=input_layer, outputs=output)

model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-3),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

"""## Training"""

callbacks = [
    EarlyStopping(patience=8, restore_best_weights=True),
    ReduceLROnPlateau(patience=4),
    ModelCheckpoint("best_ser_model.h5", save_best_only=True)
]

history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=40,
    batch_size=32,
    callbacks=callbacks
)

"""## Evaluation"""

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

print(classification_report(y_true, y_pred_classes))

cm = confusion_matrix(y_true, y_pred_classes)

plt.figure(figsize=(6,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.show()

"""## Save Model"""

model.save("final_ser_model.keras")

"""## Inference Test Cell"""

# ============================================================
# 12. INFERENCE TEST
# ============================================================

sample = X_test[3:4]
prediction = model.predict(sample)

class_map = {
    0: "Angry",
    1: "Happy",
    2: "Sad",
    3: "Disgust"
}

print("Predicted:", class_map[np.argmax(prediction)])
print("Confidence:", np.max(prediction))

"""## Upload & Predict Emotion"""

model.save("final_ser_model_copy.keras")

# ============================================================
# UPLOAD AUDIO FILE AND PREDICT EMOTION
# ============================================================

from google.colab import files
import numpy as np
import librosa
import joblib
import tensorflow as tf

# -----------------------------
# 1. Upload MP3 or WAV file
# -----------------------------
uploaded = files.upload()

file_name = list(uploaded.keys())[0]
print("Uploaded file:", file_name)

# -----------------------------
# 2. Load model and scaler
# -----------------------------
model = tf.keras.models.load_model("final_ser_model_copy.keras")
scaler = joblib.load("scaler.pkl")

# -----------------------------
# 3. Feature Extraction (Same as Training)
# -----------------------------
SAMPLE_RATE = 16000
N_MFCC = 40
MAX_FRAMES = 400

def extract_features(file_path):
    y, sr = librosa.load(file_path, sr=SAMPLE_RATE)

    # Trim silence
    y, _ = librosa.effects.trim(y)

    # Extract MFCC
    mfcc = librosa.feature.mfcc(
        y=y,
        sr=sr,
        n_mfcc=N_MFCC,
        n_fft=400,
        hop_length=160
    )

    delta = librosa.feature.delta(mfcc)
    delta2 = librosa.feature.delta(mfcc, order=2)

    features = np.vstack([mfcc, delta, delta2])
    features = features.T  # (T, 120)

    return features

# -----------------------------
# 4. Pad or Truncate
# -----------------------------
def pad_or_truncate(features):
    if features.shape[0] > MAX_FRAMES:
        return features[:MAX_FRAMES]
    else:
        pad_width = MAX_FRAMES - features.shape[0]
        return np.pad(features, ((0, pad_width), (0, 0)), mode='constant')

features = extract_features(file_name)
features = pad_or_truncate(features)

# -----------------------------
# 5. Scale features
# -----------------------------
features_reshaped = features.reshape(-1, features.shape[-1])
features_scaled = scaler.transform(features_reshaped).reshape(1, MAX_FRAMES, 120)

# -----------------------------
# 6. Predict
# -----------------------------
prediction = model.predict(features_scaled)
predicted_class = np.argmax(prediction)
confidence = np.max(prediction)

class_map = {
    0: "Angry",
    1: "Happy",
    2: "Sad",
    3: "Disgust"
}

print("\nğŸ­ Predicted Emotion:", class_map[predicted_class])
print("ğŸ” Confidence:", round(float(confidence), 4))

# ============================================================
# UPLOAD AUDIO FILE AND PREDICT EMOTION
# ============================================================

from google.colab import files
import numpy as np
import librosa
import joblib
import tensorflow as tf

# -----------------------------
# 1. Upload MP3 or WAV file
# -----------------------------
uploaded = files.upload()

file_name = list(uploaded.keys())[0]
print("Uploaded file:", file_name)

# -----------------------------
# 2. Load model and scaler
# -----------------------------
model = tf.keras.models.load_model("final_ser_model_copy.keras")
scaler = joblib.load("scaler.pkl")

# -----------------------------
# 3. Feature Extraction (Same as Training)
# -----------------------------
SAMPLE_RATE = 16000
N_MFCC = 40
MAX_FRAMES = 400

def extract_features(file_path):
    y, sr = librosa.load(file_path, sr=SAMPLE_RATE)

    # Trim silence
    y, _ = librosa.effects.trim(y)

    # Extract MFCC
    mfcc = librosa.feature.mfcc(
        y=y,
        sr=sr,
        n_mfcc=N_MFCC,
        n_fft=400,
        hop_length=160
    )

    delta = librosa.feature.delta(mfcc)
    delta2 = librosa.feature.delta(mfcc, order=2)

    features = np.vstack([mfcc, delta, delta2])
    features = features.T  # (T, 120)

    return features

# -----------------------------
# 4. Pad or Truncate
# -----------------------------
def pad_or_truncate(features):
    if features.shape[0] > MAX_FRAMES:
        return features[:MAX_FRAMES]
    else:
        pad_width = MAX_FRAMES - features.shape[0]
        return np.pad(features, ((0, pad_width), (0, 0)), mode='constant')

features = extract_features(file_name)
features = pad_or_truncate(features)

# -----------------------------
# 5. Scale features
# -----------------------------
features_reshaped = features.reshape(-1, features.shape[-1])
features_scaled = scaler.transform(features_reshaped).reshape(1, MAX_FRAMES, 120)

# -----------------------------
# 6. Predict
# -----------------------------
prediction = model.predict(features_scaled)
predicted_class = np.argmax(prediction)
confidence = np.max(prediction)

class_map = {
    0: "Angry",
    1: "Happy",
    2: "Sad",
    3: "Disgust"
}

print("\nğŸ­ Predicted Emotion:", class_map[predicted_class])
print("ğŸ” Confidence:", round(float(confidence), 4))